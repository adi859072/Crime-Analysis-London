{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n"
      ],
      "metadata": {
        "id": "8e9k3cJZpDjp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data\n",
        "file_path = '/content/crime_2025.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values initially\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "NvNP4EvfOgGI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Month_Year to datetime and extract components\n",
        "df['Month_Year'] = pd.to_datetime(df['Month_Year'], format='%d/%m/%Y', errors='coerce')\n",
        "df['Year'] = df['Month_Year'].dt.year\n",
        "df['Month'] = df['Month_Year'].dt.month\n",
        "df['Day'] = df['Month_Year'].dt.day\n",
        "\n",
        "# Function to process Financial Year and FY Index\n",
        "def process_fy_fyindex(fy_index):\n",
        "    match = re.match(r'(\\d{2}-\\d{2})_(\\d+)', str(fy_index))\n",
        "    if match:\n",
        "        fy_raw = match.group(1)\n",
        "        index = int(match.group(2))\n",
        "        fy_match = re.match(r'(\\d{2})-(\\d{2})', fy_raw)\n",
        "        if fy_match:\n",
        "            fy_start = int(\"20\" + fy_match.group(1))\n",
        "            fy_end = int(\"20\" + fy_match.group(2))\n",
        "            return f\"{fy_start}-{fy_end}\", fy_start, fy_end, index\n",
        "    return None, None, None, None"
      ],
      "metadata": {
        "id": "TDJkKJD2Oslo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply FY processing\n",
        "df[['Financial Year Cleaned', 'FY_Start', 'FY_End', 'FY_Index']] = df['FY_FYIndex'].apply(\n",
        "    lambda x: pd.Series(process_fy_fyindex(x))\n",
        ")\n",
        "\n",
        "# Convert categorical columns\n",
        "categorical_columns = ['Area Type', 'Borough_SNT', 'Area name', 'Area code',\n",
        "                       'Offence Group', 'Offence Subgroup', 'Measure']\n",
        "for col in categorical_columns:\n",
        "    df[col] = df[col].astype(str)  # Ensure type is consistent for encoding\n",
        "\n",
        "# Store encoders for decoding later\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Ensure Count is numeric\n",
        "df['Count'] = pd.to_numeric(df['Count'], errors='coerce')\n",
        "df.dropna(subset=['Count'], inplace=True)  # Drop if Count couldn't be converted"
      ],
      "metadata": {
        "id": "3c6fIO8zOx6V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates and reset index\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop unnecessary columns, including 'FY_FYIndex'\n",
        "drop_columns = [\"Month_Year\", \"Refresh Date\", \"Financial Year Cleaned\", \"FY_Start\", \"FY_End\", \"FY_Index\", \"FY_FYIndex\"]\n",
        "df.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
        "\n",
        "# Create date-based features\n",
        "df[\"Date\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
        "df[\"Year_Month\"] = df[\"Year\"] + df[\"Month\"] / 12.0\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=[\"Count\", \"Date\"])\n",
        "y = df[\"Count\"]\n",
        "\n",
        "\n",
        "# Explicitly select only numerical features for scaling\n",
        "X = X.select_dtypes(include=['number'])\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split (no shuffle to simulate time series)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, shuffle=False)\n"
      ],
      "metadata": {
        "id": "kZJqK3iZO6rM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KNN MODEL ---\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"KNN MAE:\", mean_absolute_error(y_test, y_pred_knn))\n",
        "print(\"KNN R² Score:\", r2_score(y_test, y_pred_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAr60lXePBCh",
        "outputId": "f8503976-3fe2-4979-bfe9-87ce60addab4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN MAE: 5.813739426429623\n",
            "KNN R² Score: 0.46969322944831593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RANDOM FOREST MODEL ---\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest R² Score:\", r2_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HebC4cA2PEo7",
        "outputId": "91bc04a9-2be6-45c4-da0c-adedd32c9f4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest R² Score: 0.9470105863706114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FUTURE PREDICTION FOR 2025 ---\n",
        "latest_year = df[\"Year\"].max()\n",
        "future_data = df[df[\"Year\"] == latest_year].copy()\n",
        "future_data[\"Year\"] = 2025\n",
        "\n",
        "# Select only numerical features for future data as well\n",
        "future_X = future_data.drop(columns=[\"Count\", \"Date\"]).select_dtypes(include=['number'])\n",
        "\n",
        "future_X = scaler.transform(future_X)\n",
        "\n",
        "# Predict using Random Forest\n",
        "future_predictions = rf.predict(future_X)\n",
        "future_data[\"Predicted Crime Count\"] = future_predictions\n",
        "\n",
        "# Decode categorical columns\n",
        "decoded_future_data = future_data.copy()\n",
        "for col, le in label_encoders.items():\n",
        "    if col in decoded_future_data.columns:\n",
        "        decoded_future_data[col] = le.inverse_transform(decoded_future_data[col].astype(int))\n",
        "\n",
        "# Add Year-Month\n",
        "decoded_future_data[\"Year-Month\"] = decoded_future_data[\"Year\"].astype(str) + '-' + decoded_future_data[\"Month\"].astype(str).str.zfill(2)\n",
        "\n",
        "# Output columns\n",
        "output_columns = ['Year', 'Month', 'Year-Month', 'Area name', 'Area Type',\n",
        "                  'Borough_SNT', 'Area code', 'Offence Group', 'Predicted Crime Count']\n",
        "\n",
        "# Print and save\n",
        "print(\"\\n--- Predicted Crime Data for 2025 ---\")\n",
        "print(decoded_future_data[output_columns].to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "output_filename = \"/content/future_crime_predictions_2025.csv\"\n",
        "decoded_future_data[output_columns].to_csv(output_filename, index=False)\n",
        "\n",
        "# Enable download in Colab\n",
        "from google.colab import files\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRIKGHo3POat",
        "outputId": "74beb9b0-dbe4-4cd5-a79b-66d1b2ab2348"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predicted Crime Data for 2025 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode Borough_SNT if it's still encoded\n",
        "df['Borough_SNT_Decoded'] = label_encoders['Borough_SNT'].inverse_transform(df['Borough_SNT'])\n",
        "\n",
        "# Group by decoded Borough_SNT and sum the Count\n",
        "crime_by_borough = df.groupby('Borough_SNT_Decoded')['Count'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Display top Borough\n",
        "print(\"Borough with the most crimes:\")\n",
        "print(crime_by_borough.head(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgIsEMyVycWh",
        "outputId": "c8bd2402-ec22-4761-8528-bd5ddeadf583"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Borough with the most crimes:\n",
            "Borough_SNT_Decoded\n",
            "Westminster    326808\n",
            "Name: Count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the current notebook (optional but safe)\n",
        "import IPython\n",
        "IPython.display.display(IPython.display.Javascript('IPython.notebook.save_checkpoint();'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tLKlQbmRYp7L",
        "outputId": "bbd72b5b-1e75-4c1b-db94-92a388f55b02"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "IPython.notebook.save_checkpoint();"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/prediction.ipynb\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nSpxmRpP_L2",
        "outputId": "f4730c8b-bdd7-4eb2-c4af-dd6b23f1ef52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/prediction.ipynb to html\n",
            "[NbConvertApp] Writing 310870 bytes to /content/prediction.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ONAcDHKJYPEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}